---
title: "Hausaufgabe 4 / Lena Hentschel"
output:
  html_document:
    df_print: paged
---

Bitte erstellen Sie ein Notebook mit weiteren Features (Alter, Geschlecht und Klasse sind als Beispiel in meinem Notebook auf GitHub)

# Libraries und Daten
```{r}
library(tidyverse)
library(e1071)
library(caret)
library(pROC)
```

```{r}
titanic <- read_delim("titanic.csv", ";", 
    escape_double = FALSE, trim_ws = TRUE)
```


```{r}
titanic %>%
  group_by(survived) %>%
  summarize(n = n())
```
1. Algorhithmus

```{r}
(titanic.df <- titanic %>%
  select(survived,pclass,age,sex, embarked,parch,sibsp))
```
```{r}
titanic.df <- titanic.df %>%
  mutate(age = as.numeric(str_replace(age,",",".")))
```
```{r}
titanic.df <- titanic.df %>%
  mutate(parch = as.numeric(str_replace(parch,",",".")))
```
```{r}
titanic.df <- titanic.df %>%
  mutate(sibsp = as.numeric(str_replace(sibsp,",",".")))
```
```{r}
titanic.df <- na.omit(titanic.df)
```
```{r}
titanic.df <- titanic.df %>%
  mutate(sex = ifelse(sex == "female", 1, 0))
```
```{r}
titanic.df <- titanic.df %>%
  mutate(embarked = ifelse(embarked == "S", 1, 0))
```

```{r}
set.seed(107)
inTrain <- createDataPartition(
  y = titanic.df$survived,
  p = .8,
  list = FALSE)
training <- titanic.df[ inTrain,]
testing  <- titanic.df[-inTrain,]
```
```{r}
model <- svm(survived ~ ., data = training)
summary(model)
pred <- predict(model, testing[,-1], probability = FALSE)
```
```{r}
(test.results <- cbind(pred, testing))
```
```{r}
test.results2 <- test.results %>%
  mutate(pred = ifelse(pred>=0.5,1,0))
table(test.results2$pred, testing$survived)
```
```{r}
pROC_obj <- roc(test.results$survived, test.results$pred,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```
2. Algorhithmus (Naive Bayes)
```{r}
my_training <- training %>%
  mutate(survived = as.factor(survived))%>%
  mutate(sex = as.factor(sex))%>%
  mutate(pclass = as.factor(pclass)) %>%
  mutate(parch = as.factor(parch)) %>%
  mutate(sibsp = as.factor(sibsp)) %>%
  mutate(embarked = as.factor(embarked)) %>%
  mutate(age = as.factor(age))
model <- naiveBayes(survived ~ ., data = my_training)
model
```

```{r}
my_testing <- testing %>%
  mutate(sex = as.factor(sex)) %>%
  mutate(pclass = as.factor(pclass)) %>%
  mutate(embarked = as.factor(embarked)) %>%
  mutate(parch = as.factor(parch)) %>%
  mutate(sibsp = as.factor(sibsp)) %>%
  mutate(age = as.factor(age))
pred <- predict(model, my_testing)
table(pred, my_testing$survived)
```


```{r}
(test.results <- cbind(pred, my_testing))
```

```{r}
test.results <- test.results %>%
  mutate(pred = as.numeric(pred))
pROC_obj <- roc(as.numeric(as.character(test.results$survived)), test.results$pred,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```
3. Algorithmus (Decision Tree)
```{r}
library(rpart)
library(rpart.plot)
tree<- rpart(survived~., data = training, method = 'class')
rpart.plot(tree)
```
```{r}
dt_results <- predict(tree, testing[,-1], type = 'prob')
head(model.results.dt <- cbind(testing,dt_results),500)
```
```{r}
test.results2 <- test.results %>%
  mutate(pred = ifelse(pred>=0.5,1,0))
table(test.results2$pred, testing$survived)
```

```{r}
pROC_obj <- roc(model.results.dt$survived,model.results.dt$`1`,
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```
Was sind die Unterschiede in der Performance der Algorithmen?

Die Performance des 1. Algorhithmus und des Decision Trees liegen sehr nah beieinander. Der Naive Bayes Algorhithmus schneidet in der Performance schlechter ab und liegt unter den beiden schon genannten. 
Die Kurve des ersten Algorhithmus ist deutlich wackeliger und unregelmäßiger, als die Kurve der anderen beiden. 
Alle AUC Werte der Algorhithmen liegen über dem Wert 0.5. Somit entscheidet das System nicht zufällig. 

Finden Sie Erklärungen dafür.

Erklärungen für die unterschiedliche Performance könnten die Funktionsweisen der drei Algorhithmen bieten. 
Der erstze Algorhitmus (Support Vector) kann braucht viele Daten und auch mit vielen verschiedenen Variablen rechnen. 

Der Decicision Tree hat eigentlich eine geringe Performanceleistung ist allerdings sehr anfällig für Overfitting, was das ähnliche Ergebnis zum ersten Algorhithmus erklären könnte. 
Der Naive Bayes Algorhithmus arbeitet meistens mit "wahr" und "falsch" Aussagen und kann somit auch mit geringen Datenmengen arbeiten. Es könnte sein, dass er durch die vielen Variablen in der Performance schlechter abschneidet. 